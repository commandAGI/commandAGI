{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to commandLAB","text":"<p>commandLAB provides a unified interface for interacting with different computing environments, making it easy to automate and control computers across various platforms.</p>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"concepts/","title":"Concepts","text":""},{"location":"concepts/#computers","title":"Computers","text":"<p>Computers are the core abstraction in commandLAB that provide a unified interface for interacting with different computing environments. They handle:</p> <ul> <li>Screen capture and observation (screenshot)</li> <li>Mouse input and state tracking (movement, clicks, scrolling, dragging)</li> <li>Keyboard input and state tracking (key presses, hotkeys, typing)</li> <li>Command execution (shell commands, timeouts) ((Coming soon))</li> <li>Window management (focus, minimize, maximize) ((Coming soon))</li> <li>Process management (start, stop, monitor) ((Coming soon))</li> <li>Clipboard operations (copy, paste) ((Coming soon))</li> <li>File system operations (read, write, delete) ((Coming soon))</li> <li>Microphone input ((Coming soon))</li> <li>Speaker output ((Coming soon))</li> </ul> <p>Available computer implementations:</p>"},{"location":"concepts/#base-computer","title":"Base Computer","text":"<ul> <li>{!BaseComputer!}: Abstract base class defining the computer interface</li> </ul>"},{"location":"concepts/#local-computers","title":"Local Computers","text":"<ul> <li>{!LocalPyAutoGUIComputer!}: Uses PyAutoGUI for local machine control</li> <li>{!LocalPynputComputer!}: Uses Pynput for local machine control with enhanced state tracking</li> </ul>"},{"location":"concepts/#vnc-computers","title":"VNC Computers","text":"<ul> <li>{!VNCComputer!}: Basic VNC implementation for remote machine control</li> </ul>"},{"location":"concepts/#docker-based-computers","title":"Docker-based Computers","text":"<ul> <li>{!BaseDockerComputer!}: Base implementation for Docker containers</li> <li>{!VNCDockerComputer!}: Docker container with VNC capabilities</li> <li>{!LXDEVNCDockerComputer!}: Docker container with LXDE desktop environment and VNC</li> </ul>"},{"location":"concepts/#kubernetes-based-computers","title":"Kubernetes-based Computers","text":"<ul> <li>{!BaseKubernetesComputer!}: Base implementation for Kubernetes pods</li> <li>{!VNCKubernetesComputer!}: Kubernetes pod with VNC capabilities</li> <li>{!LXDEVNCKubernetesComputer!}: Kubernetes pod with LXDE desktop environment and VNC</li> </ul>"},{"location":"concepts/#third-party-integration","title":"Third-party Integration","text":"<ul> <li>{!E2BDesktopComputer!}: Integration with E2B Desktop Sandbox</li> </ul>"},{"location":"concepts/#processors","title":"Processors","text":"<p>Processors are utility functions that help process and transform data for agents interacting with computers. They provide capabilities like:</p> <ul> <li>Screen parsing and text detection</li> <li>Grid overlay generation for precise location targeting </li> <li>Audio transcription (coming soon)</li> <li>Text-to-speech synthesis (coming soon)</li> </ul>"},{"location":"concepts/#screen-parser","title":"Screen Parser","text":"<p>Screen parsers analyze screenshots to detect and locate text and UI elements. They return structured information about screen contents.</p> <p>Available implementations:</p> <ul> <li>TesseractScreenParser: Uses the open-source Tesseract OCR engine</li> <li>Lightweight and runs locally</li> <li>Best for simple text detection scenarios</li> <li> <p>Requires the <code>pytesseract</code> package (<code>pip install commandLAB[pytesseract]</code>)</p> </li> <li> <p>ScreenParseAIParser: Uses the ScreenParse.ai API</p> </li> <li>More accurate text detection and element recognition</li> <li>Handles complex UI layouts and different text styles</li> <li>Requires an API key from ScreenParse.ai</li> <li>Returns normalized coordinates that are converted to pixel values</li> </ul> <p>Both parsers return:</p> <ul> <li>Text content found on screen</li> <li>Bounding boxes for each detected element</li> <li>Original screenshot data preserved</li> </ul> <p>Example usage:</p> <pre><code>from commandLAB.processors.screen_parser import parse_screenshot_tesseract\n\n# Parse a screenshot\nparsed = parse_screenshot_tesseract(screenshot_b64)\nfor element in parsed.elements:\n    print(f\"Found text '{element.text}' at {element.bounding_box}\")\n</code></pre>"},{"location":"concepts/#grid-overlay","title":"Grid Overlay","text":"<p>A utility function that overlays a coordinate grid on top of screenshots to help agents specify precise locations. This technique was pioneered by Anthropic to enable Claude to precisely locate and interact with objects on the screen.</p> <p>Example usage:</p> <pre><code>from commandLAB.processors.grid_overlay import overlay_grid\n\n# Add grid to screenshot\ngridded_image = overlay_grid(screenshot, grid_px_size=100)\n</code></pre>"},{"location":"concepts/#other-utilities","title":"Other utilities","text":""}]}